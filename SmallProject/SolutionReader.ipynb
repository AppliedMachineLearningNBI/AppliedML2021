{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AppliedML solution file reader\n",
    "\n",
    "This notebook is used for reading solutions. Note: it will only print the first 5 error messages of each check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining the folder holding the solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'solutions'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we read all the files in the folder, which correspond to the format, and verify the prediction/variablelist pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def init_entry():\n",
    "    tmp = {}\n",
    "    tmp['Classification'] = {}\n",
    "    tmp['Regression'] = {}\n",
    "    tmp['Clustering'] = {}\n",
    "    return tmp\n",
    "\n",
    "def read_filenames(directory):\n",
    "    tmp = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        full_path = f'{directory}/{filename}'\n",
    "        if not os.path.isfile(full_path) or not filename.endswith('.txt'):\n",
    "            continue\n",
    "        splitted = filename.split('_')\n",
    "        \n",
    "        project_part = splitted[0]\n",
    "        student_name = splitted[1]\n",
    "        is_varlist = splitted[-1].lower() == 'variablelist.txt'\n",
    "        implementation = splitted[-2] if is_varlist else splitted[-1].split('.txt')[0]\n",
    "        \n",
    "        if student_name not in tmp:\n",
    "            tmp[student_name] = init_entry()\n",
    "        if implementation not in tmp[student_name][project_part]:\n",
    "            tmp[student_name][project_part][implementation] = {}\n",
    "        \n",
    "        if is_varlist:\n",
    "            tmp[student_name][project_part][implementation]['vars'] = full_path\n",
    "        else:\n",
    "            tmp[student_name][project_part][implementation]['preds'] = full_path\n",
    "    return tmp\n",
    "\n",
    "all_errors = 0\n",
    "errors = 0\n",
    "def write_error(msg, cap=5):\n",
    "    global errors\n",
    "    if errors < cap:\n",
    "        print (msg)\n",
    "    errors += 1\n",
    "\n",
    "names = read_filenames(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can print the structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CarlJohnsen:\n",
      "    Classification:\n",
      "        lightgbm1:\n",
      "            preds: solutions/Classification_CarlJohnsen_lightgbm1.txt\n",
      "            vars:  solutions/Classification_CarlJohnsen_lightgbm1_VariableList.txt\n",
      "        sgd1:\n",
      "            preds: solutions/Classification_CarlJohnsen_sgd1.txt\n",
      "            vars:  solutions/Classification_CarlJohnsen_sgd1_VariableList.txt\n",
      "        tensorflow1:\n",
      "            preds: solutions/Classification_CarlJohnsen_tensorflow1.txt\n",
      "            vars:  solutions/Classification_CarlJohnsen_tensorflow1_VariableList.txt\n",
      "    Regression:\n",
      "        xgboost1:\n",
      "            preds: solutions/Regression_CarlJohnsen_xgboost1.txt\n",
      "            vars:  solutions/Regression_CarlJohnsen_xgboost1_VariableList.txt\n",
      "    Clustering:\n",
      "        scikitkmeans1:\n",
      "            preds: solutions/Clustering_CarlJohnsen_scikitkmeans1.txt\n",
      "            vars:  solutions/Clustering_CarlJohnsen_scikitkmeans1_VariableList.txt\n",
      "Files read succesfully\n"
     ]
    }
   ],
   "source": [
    "all_errors += errors\n",
    "errors = 0\n",
    "\n",
    "for name, parts in names.items():\n",
    "    print (f'{name}:')\n",
    "    for part, implementations in parts.items():\n",
    "        print (f'    {part}:')\n",
    "        if len(implementations) == 0:\n",
    "            write_error(f'        {part} does not have any files')\n",
    "        else:\n",
    "            for implementation, files in implementations.items():\n",
    "                if ('vars' not in files) and ('preds' not in files):\n",
    "                    write_error(f'            {implementation} does not have a full prediction/variablelist set')\n",
    "                else:\n",
    "                    print (f'        {implementation}:')\n",
    "                    print (f'            preds: {files[\"preds\"]}')\n",
    "                    print (f'            vars:  {files[\"vars\"]}')\n",
    "\n",
    "if errors == 0:\n",
    "    print ('Files read succesfully')\n",
    "else:\n",
    "    print (f'Reading files gave {errors} errors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we verify the VariableList files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables parsed without error\n"
     ]
    }
   ],
   "source": [
    "all_variables = ['actualInteractionsPerCrossing', 'averageInteractionsPerCrossing', 'correctedActualMu', 'correctedAverageMu', 'correctedScaledActualMu', 'correctedScaledAverageMu', 'NvtxReco', 'p_nTracks', 'p_pt_track', 'p_eta', 'p_phi', 'p_charge', 'p_qOverP', 'p_z0', 'p_d0', 'p_sigmad0', 'p_d0Sig', 'p_EptRatio', 'p_dPOverP', 'p_z0theta', 'p_etaCluster', 'p_phiCluster', 'p_eCluster', 'p_rawEtaCluster', 'p_rawPhiCluster', 'p_rawECluster', 'p_eClusterLr0', 'p_eClusterLr1', 'p_eClusterLr2', 'p_eClusterLr3', 'p_etaClusterLr1', 'p_etaClusterLr2', 'p_phiClusterLr2', 'p_eAccCluster', 'p_f0Cluster', 'p_etaCalo', 'p_phiCalo', 'p_eTileGap3Cluster', 'p_cellIndexCluster', 'p_phiModCalo', 'p_etaModCalo', 'p_dPhiTH3', 'p_R12', 'p_fTG3', 'p_weta2', 'p_Reta', 'p_Rphi', 'p_Eratio', 'p_f1', 'p_f3', 'p_Rhad', 'p_Rhad1', 'p_deltaEta1', 'p_deltaPhiRescaled2', 'p_TRTPID', 'p_TRTTrackOccupancy', 'p_numberOfInnermostPixelHits', 'p_numberOfPixelHits', 'p_numberOfSCTHits', 'p_numberOfTRTHits', 'p_numberOfTRTXenonHits', 'p_chi2', 'p_ndof', 'p_SharedMuonTrack', 'p_E7x7_Lr2', 'p_E7x7_Lr3', 'p_E_Lr0_HiG', 'p_E_Lr0_LowG', 'p_E_Lr0_MedG', 'p_E_Lr1_HiG', 'p_E_Lr1_LowG', 'p_E_Lr1_MedG', 'p_E_Lr2_HiG', 'p_E_Lr2_LowG', 'p_E_Lr2_MedG', 'p_E_Lr3_HiG', 'p_E_Lr3_LowG', 'p_E_Lr3_MedG', 'p_ambiguityType', 'p_asy1', 'p_author', 'p_barys1', 'p_core57cellsEnergyCorrection', 'p_deltaEta0', 'p_deltaEta2', 'p_deltaEta3', 'p_deltaPhi0', 'p_deltaPhi1', 'p_deltaPhi2', 'p_deltaPhi3', 'p_deltaPhiFromLastMeasurement', 'p_deltaPhiRescaled0', 'p_deltaPhiRescaled1', 'p_deltaPhiRescaled3', 'p_e1152', 'p_e132', 'p_e235', 'p_e255', 'p_e2ts1', 'p_ecore', 'p_emins1', 'p_etconeCorrBitset', 'p_ethad', 'p_ethad1', 'p_f1core', 'p_f3core', 'p_maxEcell_energy', 'p_maxEcell_gain', 'p_maxEcell_time', 'p_maxEcell_x', 'p_maxEcell_y', 'p_maxEcell_z', 'p_nCells_Lr0_HiG', 'p_nCells_Lr0_LowG', 'p_nCells_Lr0_MedG', 'p_nCells_Lr1_HiG', 'p_nCells_Lr1_LowG', 'p_nCells_Lr1_MedG', 'p_nCells_Lr2_HiG', 'p_nCells_Lr2_LowG', 'p_nCells_Lr2_MedG', 'p_nCells_Lr3_HiG', 'p_nCells_Lr3_LowG', 'p_nCells_Lr3_MedG', 'p_pos', 'p_pos7', 'p_poscs1', 'p_poscs2', 'p_ptconeCorrBitset', 'p_ptconecoreTrackPtrCorrection', 'p_r33over37allcalo', 'p_topoetconeCorrBitset', 'p_topoetconecoreConeEnergyCorrection', 'p_topoetconecoreConeSCEnergyCorrection', 'p_weta1', 'p_widths1', 'p_widths2', 'p_wtots1', 'p_e233', 'p_e237', 'p_e277', 'p_e2tsts1', 'p_ehad1', 'p_emaxs1', 'p_fracs1', 'p_DeltaE', 'p_E3x5_Lr0', 'p_E3x5_Lr1', 'p_E3x5_Lr2', 'p_E3x5_Lr3', 'p_E5x7_Lr0', 'p_E5x7_Lr1', 'p_E5x7_Lr2', 'p_E5x7_Lr3', 'p_E7x11_Lr0', 'p_E7x11_Lr1', 'p_E7x11_Lr2', 'p_E7x11_Lr3', 'p_E7x7_Lr0', 'p_E7x7_Lr1' ]\n",
    "max_variables = {\n",
    "    'Classification': 25,\n",
    "    'Regression': 15,\n",
    "    'Clustering': 10,\n",
    "}\n",
    "\n",
    "all_errors += errors\n",
    "errors = 0\n",
    "for student_name, parts in names.items():\n",
    "    for part, implementations in parts.items():\n",
    "        for implementation, files in implementations.items():\n",
    "            file = files['vars']\n",
    "            count = 0\n",
    "            with open(file, 'r') as f:\n",
    "                for line in f:\n",
    "                    var_name = line.rstrip()\n",
    "                    if var_name not in all_variables:\n",
    "                        write_error(f'Variable {var_name} not in the given variable list {file}')\n",
    "                    else:\n",
    "                        count += 1\n",
    "            if count > max_variables[part]:\n",
    "                write_error(f'Used too many variables ({count}/{max_variables[part]}) for {part}: {file}')\n",
    "                    \n",
    "if errors == 0:\n",
    "    print ('Variables parsed without error')\n",
    "else:\n",
    "    print (f'Variables had {errors} errors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can verify than the solution files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solutions parsed without error\n"
     ]
    }
   ],
   "source": [
    "test_entries = 160651\n",
    "prediction_range = {\n",
    "    'Classification': (0.0, 1.0),\n",
    "    'Regression': (-float('inf'), float('inf')),\n",
    "    'Clustering': (-float('inf'), float('inf')),\n",
    "}\n",
    "\n",
    "all_errors += errors\n",
    "errors = 0\n",
    "for student_name, parts in names.items():\n",
    "    for part, implementations in parts.items():\n",
    "        for implementation, files in implementations.items():\n",
    "            file = files['preds']\n",
    "            with open(file, 'r') as f:\n",
    "                lines = [line for line in f]\n",
    "            for i in range(len(lines)):\n",
    "                if ',' in lines[i]:\n",
    "                    index, value = lines[i].lstrip().rstrip().split(',')\n",
    "                    try:\n",
    "                        if int(index) != i:\n",
    "                            write_error(f'Index at line {i+1} does not have correct index: {index}')\n",
    "                    except ValueError:\n",
    "                        write_error(f'Unable to cast the index to an integer: {index} in {file}')\n",
    "                else:\n",
    "                    value = lines[i].lstrip().rstrip()\n",
    "                value = float(value)\n",
    "                if part == 'Clustering':\n",
    "                    if value.is_integer():\n",
    "                        value = int(value)\n",
    "                    else:\n",
    "                        write_error(f'Clustering value at {i} is not an integer: {value} in {file}')\n",
    "                        continue\n",
    "                mi, ma = prediction_range[part]\n",
    "                if not (value >= mi and value <= ma):\n",
    "                    write_error(f'Value at {i} is not in the permitted range of ({mi},{ma}): {value} in {file}')\n",
    "            if len(lines) != test_entries:\n",
    "                write_error(f'Not enough predictions. Got {len(lines)}, expected {test_entries}')\n",
    "                \n",
    "if errors == 0:\n",
    "    print ('Solutions parsed without error')\n",
    "else:\n",
    "    print (f'Solutions had {errors} errors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we check if all of the steps completed without error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All of parts of this submission had no errors\n"
     ]
    }
   ],
   "source": [
    "if all_errors == 0:\n",
    "    print ('All of parts of this submission had no errors')\n",
    "else:\n",
    "    print (f'This submission had {all_errors} errors')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
